/*
Auto-generated by: https://github.com/pmndrs/gltfjsx
Command: npx gltfjsx@6.2.3 public/models/64f1a714fe61576b46f27ca2.glb -o src/components/Avatar.jsx -k -r public
*/

import { useAnimations, useGLTF } from "@react-three/drei";
import { useFrame } from "@react-three/fiber";
import { useEffect, useRef, useState } from "react";

import { useControls } from "leva";
import * as THREE from "three";
import { VISEMES } from "wawa-lipsync";
import { lipsyncManager } from "../App";
import { BrowserAvatarTracking } from "../services/browserAvatarTracking";
import { useTTSStore } from "../stores/ttsStore";

let setupMode = false;

export function Avatar(props) {
  const gltf = useGLTF("/models/wawalipavatar.glb");
  const { nodes, materials, scene } = gltf;
  const [cameraPermission, setCameraPermission] = useState('prompt'); // 'prompt', 'granted', 'denied'
  const resolvePreferredMotionMode = () => {
    const fallback = "option4";
    if (typeof window === "undefined") {
      return fallback;
    }
    const stored =
      window.__preferredMotionMode ||
      window.localStorage?.getItem("aishaMotionMode");
    if (stored === "option1" || stored === "option2" || stored === "option3" || stored === "option4") {
      return stored;
    }
    window.localStorage?.setItem("aishaMotionMode", fallback);
    window.__preferredMotionMode = fallback;
    return fallback;
  };
  
  // Debug: Log the loaded model structure
  useEffect(() => {
    console.log("=== WAWALIPAVATAR.GLB DEBUG ===");
    console.log("Full GLTF:", gltf);
    console.log("Scene:", scene);
    console.log("Nodes:", nodes);
    console.log("Materials:", materials);
    console.log("Scene children:", scene?.children);
    
    // Log all objects in the scene
    if (scene) {
      scene.traverse((child) => {
        console.log(`- ${child.name} (${child.type})`, child);
      });
    }
  }, [gltf, scene, nodes, materials]);

  // Try to load animations, but handle gracefully if they don't exist or are incompatible
  const animationsGLTF = useGLTF("/models/animations.glb");
  
  const group = useRef();
  const trackingRef = useRef(null);
  
  // Check if the loaded avatar has its own animations
  const availableAnimations = scene.animations && scene.animations.length > 0 
    ? scene.animations 
    : (animationsGLTF.animations || []);
    
  const { actions, mixer } = useAnimations(availableAnimations, group);
  const [animation, setAnimation] = useState(() => {
    if (availableAnimations.length === 0) return null;
    // Look for "idle talk" first, then "Idle", then first available animation
    return availableAnimations.find((a) => a.name === "idle talk") 
      ? "idle talk" 
      : availableAnimations.find((a) => a.name === "Idle") 
      ? "Idle" 
      : availableAnimations[0]?.name || null;
  });

  // TTS state - automatically switch to "armature.001" when speaking
  const isSpeaking = useTTSStore((state) => state.isSpeaking);
  const savedAnimationRef = useRef(null); // Store the animation to return to after speaking
  const hasStartedTalking = useRef(false); // Track if we've actually started the talking animation

  const { smoothMovements, responsiveness, selectedAnimation, transitionDuration } = useControls("Avatar", {
    smoothMovements: {
      value: false, // Changed to false for snappier default
      label: "Smooth Movements",
    },
    responsiveness: {
      value: 0.8,
      min: 0.1,
      max: 1.0,
      step: 0.1,
      label: "Animation Speed",
    },
    transitionDuration: {
      value: 1.0,
      min: 0.1,
      max: 3.0,
      step: 0.1,
      label: "Transition Smoothness (s)",
    },
    selectedAnimation: {
      value: animation || "None",
      options: availableAnimations.length > 0 
        ? availableAnimations.reduce((acc, anim) => {
            acc[anim.name] = anim.name;
            return acc;
          }, {})
        : { "None": "None" },
      label: "Animation",
    },
  });

  // Debug: Log available animations
  useEffect(() => {
    console.log("Available animations:", availableAnimations.map(a => a.name));
    console.log("Avatar scene structure:", scene);
  }, [availableAnimations, scene]);

  // Initialize browser-based eye tracking (no backend needed!)
  // Handle camera permission request
  const requestCameraPermission = async () => {
    try {
      console.log("[Avatar] Requesting camera permission...");
      setCameraPermission('prompt');
      
      // Test camera access
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { 
          width: { ideal: 640 }, 
          height: { ideal: 480 },
          facingMode: 'user'
        } 
      });
      
      // Stop the test stream
      stream.getTracks().forEach(track => track.stop());
      
      setCameraPermission('granted');
      console.log("[Avatar] âœ… Camera permission granted");
      
      // Now initialize tracking
      initializeTracking();
      
    } catch (error) {
      console.error("[Avatar] âŒ Camera permission denied:", error);
      setCameraPermission('denied');
    }
  };

  // Initialize tracking after camera permission
  const initializeTracking = async () => {
    if (!scene || trackingRef.current) return;

    console.log("[Avatar] Initializing browser-based eye tracking...");
    try {
      const preferredMotionMode = resolvePreferredMotionMode();
      const tracker = new BrowserAvatarTracking(scene, {
        enableBlinking: false, // We handle blinking separately in the component
        enableMicroMovements: true,
        motionMode: preferredMotionMode // Respect preferred motion mode if user selected one
      });
      
      // Wait for initialization to complete
      await tracker.initialize();
      if (tracker.config) {
        tracker.config.motionMode = preferredMotionMode;
      }
      if (typeof tracker.recreateController === 'function') {
        tracker.recreateController();
      }
      trackingRef.current = tracker;
      
      console.log("[Avatar] âœ… Tracking initialized and ready!");
    } catch (error) {
      console.error("[Avatar] Failed to initialize tracking:", error);
      console.warn("[Avatar] Eye tracking unavailable - app will continue without it");
    }
  };

  useEffect(() => {
    if (!scene) return;

    // Auto-initialize on desktop, but require user interaction on mobile
    const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
    
    if (!isMobile) {
      // Desktop: try to initialize immediately
      initializeTracking();
    } else {
      // Mobile: listen for camera permission event
      const handleCameraPermissionGranted = () => {
        console.log("[Avatar] Camera permission granted, initializing tracking...");
        initializeTracking();
      };
      
      window.addEventListener('cameraPermissionGranted', handleCameraPermissionGranted);
      
      return () => {
        window.removeEventListener('cameraPermissionGranted', handleCameraPermissionGranted);
      };
    }
  }, [scene]);

  // Cleanup tracking on unmount
  useEffect(() => {
    return () => {
      if (trackingRef.current) {
        console.log("[Avatar] Cleaning up tracking...");
        if (typeof trackingRef.current.disconnect === 'function') {
          trackingRef.current.disconnect();
        }
        trackingRef.current = null;
      }
    };
  }, []);

  // Handle animation changes from the control panel
  useEffect(() => {
    if (selectedAnimation && selectedAnimation !== animation) {
      setAnimation(selectedAnimation);
    }
  }, [selectedAnimation]);
  
  // AUTO-SWITCH ANIMATION WHEN SPEAKING
  // Save current animation when TTS starts, but DON'T switch yet
  // Switch only when lipsync actually begins (in useFrame)
  useEffect(() => {
    if (isSpeaking && !savedAnimationRef.current) {
      // TTS started - save current animation but DON'T switch yet
      savedAnimationRef.current = animation;
      hasStartedTalking.current = false; // Reset flag
      console.log('[Avatar] ðŸŽ¤ TTS started - saved animation:', animation, '(waiting for lipsync to begin...)');
    } else if (!isSpeaking && savedAnimationRef.current) {
      // TTS ended - switch back to saved animation
      const previousAnim = savedAnimationRef.current;
      console.log('[Avatar] âœ… TTS ended - restoring:', previousAnim);
      savedAnimationRef.current = null; // Clear first to prevent re-triggering
      hasStartedTalking.current = false; // Reset flag
      setAnimation(previousAnim);
    }
  }, [isSpeaking, animation]);
  
  // Expose calibration and motion mode functions to window for easy access
  useEffect(() => {
    if (!trackingRef.current) {
      return;
    }

    const tracker = trackingRef.current;

    window.calibrateAisha = () => {
      if (tracker && typeof tracker.calibrate === 'function') {
        tracker.calibrate();
        console.log('[Avatar] âœ… Calibration applied! Aisha should now look straight ahead.');
      }
    };
    window.resetCalibration = () => {
      if (tracker && typeof tracker.resetCalibration === 'function') {
        tracker.resetCalibration();
        console.log('[Avatar] ðŸ”„ Calibration reset to defaults.');
      }
    };
    // Motion mode switcher for dashboard + console
    window.setMotionMode = (mode) => {
      if (!tracker) return;
      if (mode === 'option1' || mode === 'option2' || mode === 'option3' || mode === 'option4') {
        if (tracker.config) {
          tracker.config.motionMode = mode;
        }
        if (typeof tracker.recreateController === 'function') {
          tracker.recreateController();
        }
        window.__preferredMotionMode = mode;
        try {
          window.localStorage?.setItem('aishaMotionMode', mode);
        } catch (err) {
          console.warn('[Avatar] Unable to persist motion mode preference:', err);
        }
        console.log(`[Avatar] âœ… Motion mode changed to: ${mode}`);
        console.log(`  Option 1: Cascading (eyesâ†’headâ†’body)`);
        console.log(`  Option 2: Body-only (eyes/head stay forward, body turns)`);
        console.log(`  Option 3: Normalized algorithm (deadzone, natural tracking)`);
        console.log(`  Option 4: Counter-rotation (body/head follow, eyes counter-rotate)`);
      } else {
        console.warn('[Avatar] âŒ Invalid motion mode. Use "option1", "option2", "option3", or "option4"');
      }
    };

    const preferred = resolvePreferredMotionMode();
    if (preferred && typeof window.setMotionMode === 'function') {
      window.setMotionMode(preferred);
    }

    const handleMotionModeChange = (event) => {
      const mode = event?.detail?.mode;
      if (!mode || typeof window.setMotionMode !== 'function') return;
      if (mode === tracker?.config?.motionMode) return;
      window.setMotionMode(mode);
    };

    window.addEventListener('aisha-motion-mode-change', handleMotionModeChange);

    // Expose animation control function for dance emotes and other animations
    window.triggerAishaAnimation = (animationName, duration = null, returnToAnimation = null) => {
      if (!animationName) {
        console.warn('[Avatar] No animation name provided');
        return;
      }
      
      // Check if animation exists
      const animExists = availableAnimations.some(a => a.name === animationName);
      if (!animExists) {
        console.warn(`[Avatar] Animation "${animationName}" not found. Available:`, availableAnimations.map(a => a.name));
        return;
      }
      
      // Determine what animation to return to
      // If returnToAnimation is specified, use it; otherwise use current animation
      const currentAnim = animation;
      const targetReturnAnim = returnToAnimation || currentAnim;
      
      // If returnToAnimation is specified but doesn't exist, try to find an idle animation
      let finalReturnAnim = targetReturnAnim;
      if (returnToAnimation) {
        const returnAnimExists = availableAnimations.some(a => a.name === returnToAnimation);
        if (!returnAnimExists) {
          // Try to find an idle animation
          const idleAnim = availableAnimations.find(a => 
            a.name.toLowerCase().includes('idle') || 
            a.name === 'Idle' || 
            a.name === 'idle talk'
          );
          finalReturnAnim = idleAnim ? idleAnim.name : currentAnim;
          console.warn(`[Avatar] Return animation "${returnToAnimation}" not found, using "${finalReturnAnim}" instead`);
        }
      }
      
      console.log(`[Avatar] ðŸŽ¬ Triggering animation: ${animationName} (will return to ${finalReturnAnim} after ${duration || 'default'}ms)`);
      
      // Set the new animation
      setAnimation(animationName);
      
      // If duration is specified, return to target animation after that time
      if (duration && duration > 0) {
        setTimeout(() => {
          console.log(`[Avatar] ðŸŽ¬ Returning to animation: ${finalReturnAnim}`);
          setAnimation(finalReturnAnim);
        }, duration);
      }
    };

    // Listen for animation trigger events
    const handleAnimationTrigger = (event) => {
      const { animationName, duration, returnToAnimation } = event.detail || {};
      if (animationName) {
        window.triggerAishaAnimation(animationName, duration, returnToAnimation);
      }
    };

    window.addEventListener('aisha-trigger-animation', handleAnimationTrigger);

    return () => {
      delete window.calibrateAisha;
      delete window.resetCalibration;
      delete window.setMotionMode;
      delete window.triggerAishaAnimation;
      window.removeEventListener('aisha-motion-mode-change', handleMotionModeChange);
      window.removeEventListener('aisha-trigger-animation', handleAnimationTrigger);
    };
  }, [trackingRef.current, animation, availableAnimations]);
  
  // Store the current playing action for smooth crossfades
  const currentActionRef = useRef(null);
  
  useEffect(() => {
    if (animation && actions[animation]) {
      try {
        const newAction = actions[animation];
        
        // CRITICAL: Disable morph target tracks in animation to allow lipsync to work
        // Morph targets should be controlled by lipsync, not by animation
        if (newAction && newAction._clip && newAction._clip.tracks) {
          newAction._clip.tracks.forEach(track => {
            // Disable any morph target influence tracks (these override lipsync)
            if (track.name && track.name.includes('.morphTargetInfluences[')) {
              track.enabled = false;
            }
          });
        }
        
        // Smooth crossfade between animations using Three.js built-in crossfade
        if (currentActionRef.current && currentActionRef.current !== newAction) {
          // Crossfade from current to new animation with configurable duration
          const fadeDuration = transitionDuration || 1.0;
          
          // Prepare the new action
          newAction.reset();
          newAction.setEffectiveTimeScale(1);
          newAction.setEffectiveWeight(1);
          newAction.play();
          
          // Crossfade from old to new (smooth bone-level blending)
          currentActionRef.current.crossFadeTo(newAction, fadeDuration, true);
          
          console.log(`[Avatar] ðŸŽ¬ Smooth crossfade (${fadeDuration.toFixed(1)}s):`, currentActionRef.current._clip.name, 'â†’', newAction._clip.name);
        } else if (!currentActionRef.current) {
          // First time playing - just start the animation
          newAction.reset().fadeIn(transitionDuration * 0.5 || 0.5).play();
          console.log('[Avatar] â–¶ï¸ Starting animation:', newAction._clip.name);
        }
        
        currentActionRef.current = newAction;
          
      } catch (error) {
        console.warn(`Animation ${animation} failed to play:`, error);
      }
    }
  }, [animation, actions]);

  // Cache morph target mappings for better performance
  const morphTargetCache = useRef({});
  
  const lerpMorphTarget = (target, value, speed = 0.3) => {
    scene.traverse((child) => {
      if (child.isSkinnedMesh && child.morphTargetDictionary) {
        const cacheKey = `${child.name}-${target}`;
        
        // Check cache first
        if (morphTargetCache.current[cacheKey] !== undefined) {
          const index = morphTargetCache.current[cacheKey];
          if (index !== -1 && child.morphTargetInfluences[index] !== undefined) {
            child.morphTargetInfluences[index] = THREE.MathUtils.lerp(
              child.morphTargetInfluences[index],
              value,
              speed
            );
          }
          return;
        }
        
        let targetIndex = child.morphTargetDictionary[target];
        
        if (targetIndex === undefined) {
          // Try alternatives only once and cache the result
          const alternatives = {
            'aa': ['mouthOpen', 'jawOpen', 'mouth_open', 'jaw_open'],
            'E': ['mouthSmile', 'mouth_smile', 'mouthLeft', 'mouth_left'],
            'I': ['mouthClose', 'mouth_close', 'mouthRight', 'mouth_right'],
            'O': ['mouthFunnel', 'mouth_funnel', 'mouthPucker', 'mouth_pucker'],
            'U': ['mouthPucker', 'mouth_pucker', 'mouthFunnel', 'mouth_funnel']
          };
          
          if (alternatives[target]) {
            for (const alt of alternatives[target]) {
              const altIndex = child.morphTargetDictionary[alt];
              if (altIndex !== undefined && child.morphTargetInfluences[altIndex] !== undefined) {
                targetIndex = altIndex;
                break;
              }
            }
          }
        }
        
        // Cache the result (even if -1 for not found)
        morphTargetCache.current[cacheKey] = targetIndex || -1;
        
        if (targetIndex !== undefined && child.morphTargetInfluences[targetIndex] !== undefined) {
          child.morphTargetInfluences[targetIndex] = THREE.MathUtils.lerp(
            child.morphTargetInfluences[targetIndex],
            value,
            speed
          );

          if (!setupMode) {
            try {
              set({
                [target]: value,
              });
            } catch (e) {}
          }
        }
      }
    });
  };

  const [blink, setBlink] = useState(false);
  const [blinkLeft, setBlinkLeft] = useState(false);
  const [blinkRight, setBlinkRight] = useState(false);
  const [winkLeft, setWinkLeft] = useState(false);
  const [winkRight, setWinkRight] = useState(false);

  useFrame(() => {
    // Eye blinking with tiny delay between eyes for realism
    // Left eye blinks slightly before right (or vice versa, random)
    lerpMorphTarget("eyeBlinkLeft", blinkLeft || blink || winkLeft ? 1 : 0, 0.5);
    lerpMorphTarget("eyeBlinkRight", blinkRight || blink || winkRight ? 1 : 0, 0.5);

    // LIPSYNC - exactly like it was working before
    if (setupMode) {
      return;
    }

    const viseme = lipsyncManager.viseme;
    const state = lipsyncManager.state;
    const features = lipsyncManager.features;
    
    // ðŸŽ¬ REALISTIC ANIMATION SWITCH: Switch to talking animation ONLY when lipsync actually starts
    if (isSpeaking && !hasStartedTalking.current && savedAnimationRef.current) {
      // Check if lipsync has actually started (volume above threshold)
      if (features && features.volume > 0.05) {
        // Find talking animation (look for "Armature.001" in the name)
        const talkingAnimation = availableAnimations.find(a => 
          a.name.toLowerCase().includes("armature.001")
        );
        
        if (talkingAnimation) {
          hasStartedTalking.current = true; // Mark as switched
          console.log('[Avatar] ðŸŽ¬ Lipsync detected! Switching to talking animation:', talkingAnimation.name);
          setAnimation(talkingAnimation.name);
        }
      }
    }
    
    // Use the responsiveness slider for animation speed - optimized for TTS
    const baseSpeed = responsiveness;
    // Much faster speeds for TTS audio sync
    const activeSpeed = smoothMovements ? (state === "vowel" ? baseSpeed * 1.2 : baseSpeed * 1.5) : baseSpeed * 2.0;
    const deactiveSpeed = smoothMovements ? (state === "vowel" ? baseSpeed * 1.0 : baseSpeed * 1.2) : baseSpeed * 1.8;
    
    lerpMorphTarget(viseme, 1, activeSpeed);

    Object.values(VISEMES).forEach((value) => {
      if (viseme === value) {
        return;
      }
      lerpMorphTarget(value, 0, deactiveSpeed);
    });
    
    // Apply face tracking AFTER animations (so it overrides animation bone rotations)
    if (trackingRef.current && typeof trackingRef.current.applyTracking === 'function') {
      trackingRef.current.applyTracking();
    }
  });

  useEffect(() => {
    let blinkTimeout;
    let leftTimeout;
    let rightTimeout;
    
    const nextBlink = () => {
      blinkTimeout = setTimeout(() => {
        // Randomly choose which eye blinks first (tiny delay: 10-30ms)
        const firstEye = Math.random() < 0.5 ? 'left' : 'right';
        const delay = THREE.MathUtils.randFloat(10, 30); // Fractional delay (10-30ms)
        
        if (firstEye === 'left') {
          // Left eye blinks first, right follows
          setBlinkLeft(true);
          rightTimeout = setTimeout(() => {
            setBlinkRight(true);
          }, delay);
        } else {
          // Right eye blinks first, left follows
          setBlinkRight(true);
          leftTimeout = setTimeout(() => {
            setBlinkLeft(true);
          }, delay);
        }
        
        // Open both eyes after blink duration
        setTimeout(() => {
          setBlinkLeft(false);
          setBlinkRight(false);
          nextBlink();
        }, 200);
      }, THREE.MathUtils.randInt(1000, 5000));
    };
    
    nextBlink();
    
    return () => {
      clearTimeout(blinkTimeout);
      clearTimeout(leftTimeout);
      clearTimeout(rightTimeout);
    };
  }, []);

  // Function to safely render mesh if it exists
  const renderMesh = (nodeName, materialName, withMorphTargets = false) => {
    const node = nodes[nodeName];
    const material = materials[materialName];
    
    if (!node || !node.geometry || !material) {
      return null;
    }

    const meshProps = {
      name: nodeName,
      geometry: node.geometry,
      material: material,
      skeleton: node.skeleton,
    };

    if (withMorphTargets && node.morphTargetDictionary && node.morphTargetInfluences) {
      meshProps.morphTargetDictionary = node.morphTargetDictionary;
      meshProps.morphTargetInfluences = node.morphTargetInfluences;
    }

    return <skinnedMesh key={nodeName} {...meshProps} />;
  };

  return (
    <group {...props} dispose={null} ref={group}>
      {scene ? (
        // Just render the entire scene as-is for now
        <primitive object={scene} />
      ) : (
        // Fallback: render a simple cube to show something is there
        <mesh>
          <boxGeometry args={[1, 1, 1]} />
          <meshStandardMaterial color="red" />
        </mesh>
      )}
    </group>
  );
}

useGLTF.preload("/models/wawalipavatar.glb");
// Preload animations but don't fail if they don't exist
try {
  useGLTF.preload("/models/animations.glb");
} catch (error) {
  console.warn("Could not preload animations.glb:", error);
}
